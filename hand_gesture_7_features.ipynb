{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c13160f2",
   "metadata": {},
   "source": [
    "# Quantitative Assessment of Surgical Skills based on Muscular Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce26140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "from os.path import dirname, join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb0652f",
   "metadata": {},
   "source": [
    "### importing and formating the data from matlab : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e11374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exe_to_global_label(restimulus, inden):\n",
    "    \"\"\"\n",
    "    this will take the label of ex2  or ex3 and convert it to a global label system\n",
    "    the global label system is uniform for ex1,2 and 3 and goes from 0 to 52 \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(restimulus)):\n",
    "        if restimulus[i] != 0:\n",
    "            restimulus[i] += inden \n",
    "        else:\n",
    "            restimulus[i]=0\n",
    "    return restimulus \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3b213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63eb9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fb7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n):\n",
    "   \n",
    "    \"\"\"\n",
    "    return the emg data and corresponding restimulus (for the 3 exos) of the n-th person\n",
    "    \"\"\"\n",
    "    data_dir = pjoin('db_1', 'data', f's{n}')\n",
    "    \n",
    "    file_name_e1 = pjoin(data_dir, f'S{n}_A1_E1.mat')\n",
    "    file_name_e2 = pjoin(data_dir, f'S{n}_A1_E2.mat')\n",
    "    file_name_e3 = pjoin(data_dir, f'S{n}_A1_E3.mat')\n",
    "    \n",
    "    contents_e1 = sio.loadmat(file_name_e1)\n",
    "    contents_e2 = sio.loadmat(file_name_e2)\n",
    "    contents_e3 = sio.loadmat(file_name_e3)\n",
    "    \n",
    "    # those are np.array \n",
    "    emg_1 = contents_e1['emg']\n",
    "    emg_2 = contents_e2['emg']\n",
    "    emg_3 = contents_e3['emg']\n",
    "\n",
    "    lbl_1 = contents_e1['restimulus']\n",
    "    lbl_2 = contents_e2['restimulus']\n",
    "    lbl_3 = contents_e3['restimulus']\n",
    "\n",
    "    lbl_2 = exe_to_global_label(lbl_2,12) # so transforming the label into 13-29 (as 1-12 are already taken by ex_1)\n",
    "    lbl_3 = exe_to_global_label(lbl_3,29) # so transforming the label into 30-52 (as 1-29are already taken by ex_1 and ex_2)  \n",
    "\n",
    "    emg = np.concatenate((emg_1,emg_2,emg_3))\n",
    "    labels = np.concatenate((lbl_1,lbl_2,lbl_3))\n",
    "    \n",
    "    return emg ,labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45b0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4612696, 10)\n",
      "(4612696, 1)\n"
     ]
    }
   ],
   "source": [
    "# concatenating the datas from all the subjects \n",
    "nb_subjects = 10 \n",
    "emg= np.empty((0,10))\n",
    "labels = np.empty((0,1))\n",
    "for i in range(1,nb_subjects+1):\n",
    "    emg_sub , labels_sub = get_data(i)\n",
    "    emg = np.concatenate((emg,emg_sub))\n",
    "    labels = np.concatenate((labels,labels_sub))\n",
    "    \n",
    "print(emg.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "nb_channel = 10 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67f2c66f",
   "metadata": {},
   "source": [
    "### separating the data by repetition : \n",
    "Think about the fact that the rest state will way more present than the other ones. Do we need to do something about it during training ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9033189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class repet():\n",
    "    def __init__(self,emg,label):\n",
    "        self.emg = emg\n",
    "        self.label = label\n",
    "        \n",
    "        \n",
    "class segment():\n",
    "    \n",
    "    def __init__(self,emg,label,nb_channel= 10):\n",
    "        self.emg = emg\n",
    "        self.label = label \n",
    "        self.nb_channel= nb_channel\n",
    "        \n",
    "    def mav(self):\n",
    "        emg=self.emg\n",
    "        nb_channel = self.nb_channel\n",
    "        emg = np.absolute(emg)\n",
    "        n  = emg.shape[0]\n",
    "        mav=np.empty((1,nb_channel))\n",
    "        for i in range(nb_channel):# for each channel\n",
    "            mav[0][i] = (1/n)* np.sum(emg[i],axis = 0)\n",
    "        return mav  \n",
    "    \n",
    "    def iemg(self):\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        emg = np.absolute(emg)\n",
    "        nb_channel = self.nb_channel\n",
    "        iemg=np.empty((1,nb_channel))\n",
    "        for i in range(nb_channel):# for each channel\n",
    "            iemg[0][i] = np.sum(emg[i],axis = 0)\n",
    "        return iemg\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        emg = np.absolute(emg)\n",
    "        nb_channel = self.nb_channel\n",
    "        iemg=np.empty((1,nb_channel))\n",
    "        for i in range(0,nb_channel):\n",
    "            iemg[0][i]= np.sum(emg[i])\n",
    "        return iemg\n",
    "    \n",
    "    def ssi(self):\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        emg = np.absolute(emg)\n",
    "        nb_channel = self.nb_channel\n",
    "        ssi=np.empty((1,nb_channel))\n",
    "        n  = emg.shape[0]\n",
    "        for i in range(nb_channel): # for each channel\n",
    "            for j in range(n):\n",
    "                emg[j][i] = emg[j][i]*emg[j][i]\n",
    "            ssi[0][i] = np.sum(emg[i],axis=0)\n",
    "        return ssi\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        emg = np.square(emg)\n",
    "        nb_channel = self.nb_channel\n",
    "        ssi=np.empty((1,nb_channel))\n",
    "        for i in range(0,nb_channel):\n",
    "            ssi[0][i]=np.sum(emg[i],axis=0)\n",
    "        return ssi  \n",
    "        \n",
    "        \n",
    "        \n",
    "    def rms(self):\n",
    "        \"\"\"\n",
    "        n  = emg.shape[0]  #number of samples \n",
    "        nb_channel = self.nb_channel\n",
    "        rms=np.empty((1,nb_channel))\n",
    "        for i in range(nb_channel):\n",
    "            rms[0][i]=((1/n) * self.ssi()[0][i])**(0.5)\n",
    "        return rms\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        n  = emg.shape[0]  #number of samples \n",
    "        nb_channel = self.nb_channel\n",
    "        rms=np.empty((1,nb_channel))\n",
    "        emg = np.square(emg)\n",
    "        \n",
    "        for i in range(0,nb_channel):\n",
    "            rms[0][i]= ((1/n)*np.sum(emg[i]))**(0.5)\n",
    "        return rms \n",
    "        \n",
    "   \n",
    "    def var(self):\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        n= emg.shape[0] #number of samples \n",
    "        nb_channel = self.nb_channel\n",
    "        var = np.empty((1,nb_channel))\n",
    "        \n",
    "        for i in range(nb_channel):\n",
    "            summation = 0\n",
    "            mean_channel = np.mean(emg[:][i],axis= 0)\n",
    "            for j in range(n):\n",
    "                summation += (emg[j][i]-mean_channel)**2\n",
    "            var[0][i] = (1/n)*summation\n",
    "        \"\"\"\n",
    "        emg=self.emg\n",
    "        nb_channel = self.nb_channel\n",
    "        var = np.empty((1,nb_channel))\n",
    "        for i in range(0,nb_channel):\n",
    "            var[0][i]=np.var(emg[i])\n",
    "        return var\n",
    "    \n",
    "    def ssc(self, x_thresh = 0.001): \n",
    "        emg=self.emg\n",
    "        nb_channel = self.nb_channel\n",
    "        ssc = np.empty((1,nb_channel))\n",
    "        n= emg.shape[0] #number of samples \n",
    "        \n",
    "        for i in range (nb_channel):\n",
    "            f_i = 0  \n",
    "            for j in range(1,n-1):\n",
    "                cond_1 = emg[j][i]>emg[j-1][i] and emg[j][i]>emg[j+1][i]\n",
    "                cond_2 = emg[j][i]<emg[j-1][i] and emg[j][i]<emg[j+1][i]\n",
    "                cond_3 = abs(emg[j][i]- emg[j+1][i])> x_thresh\n",
    "                cond_4 = abs(emg[j][i]- emg[j-1][i])> x_thresh\n",
    "                if cond_1 or cond_2 or cond_3 or cond_4:\n",
    "                    f_i += 1\n",
    "            ssc[0][i] = (1/n)*f_i\n",
    "        return ssc\n",
    "    \n",
    "    def zc(self, x_thresh = 0.0001): #zero crossings\n",
    "        emg=self.emg\n",
    "        nb_channel = self.nb_channel\n",
    "        zc = np.empty((1,nb_channel))\n",
    "        n= emg.shape[0] #number of samples \n",
    "        \n",
    "        for i in range(nb_channel):\n",
    "            f_i = 0 \n",
    "            for j in range(n-1):\n",
    "                cond_1 = emg[j][i]*emg[j+1][i]>0\n",
    "                cond_2 = abs(emg[j][i] - emg[j+1][i])>x_thresh\n",
    "                if cond_1 and cond_2 :\n",
    "                    f_i += 1\n",
    "                zc[0][i] = (1/n)*f_i\n",
    "        return zc\n",
    "      \n",
    "    def get_features_by_channel(self,channel_nb):\n",
    "        #return the all the features of this segment (for a given channel)\n",
    "        feature_list = np.empty((0))\n",
    "        \n",
    "        feature_list = np.append(feature_list,self.mav()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.iemg()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.ssi()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.rms()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.var()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.ssc()[0][channel_nb])\n",
    "        feature_list = np.append(feature_list,self.zc()[0][channel_nb])\n",
    "        \n",
    "        \n",
    "        \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a88241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_repetition(emg,labels):\n",
    "   \n",
    "    \"\"\"\n",
    "    we have 53 possible class (52 movements and 1 for the rest state)\n",
    "    \n",
    "    input : - emg data of all the participant concatenated \n",
    "            - restimulus data , so the label corresponding to the emg data \n",
    "            \n",
    "    output : - a 1-D list of repet elements\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_samples = len(labels)\n",
    "    \n",
    "    print(\"Number of samples : \" , nb_samples)\n",
    "    list_repet = np.empty((0))\n",
    "    \n",
    "    accum = 0 \n",
    "    current_lbl = 0 \n",
    "    for i in range(nb_samples):\n",
    "        if current_lbl == labels[i]:\n",
    "            accum += 1\n",
    "        else :\n",
    "            diff = i - accum\n",
    "            new_rep = repet(emg[diff:i],labels[i])\n",
    "            \n",
    "            list_repet = np.append(list_repet, new_rep)\n",
    "            \n",
    "            current_lbl = labels[i]\n",
    "            accum = 0 \n",
    "    return list_repet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614cb77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples :  4612696\n",
      "(10400,)\n"
     ]
    }
   ],
   "source": [
    "list_repetition = separate_repetition(emg,labels)\n",
    "print(list_repetition.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf55a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(list_repet, window_type = 'adjacent', length = 256):\n",
    "   \n",
    "    \"\"\"\n",
    "    input : - the list a the emg data separated by repetition \n",
    "            - a param window_type (either adjacent or overlapped)(see \"Myoelectric control systems— A survey\")\n",
    "            - the length of each window\n",
    "    output : - a list of all the segments for all the exercice and all subjects\n",
    "    \"\"\"\n",
    "    nb_repet = len(list_repet)\n",
    "    print(\"We have \" , nb_repet , \"repetitions of excercices in the data\")\n",
    "    \n",
    "    seg_data = np.empty((0))\n",
    "    \n",
    "    if window_type == 'adjacent': \n",
    "        \n",
    "        for i in range(nb_repet):\n",
    "            nb_windows = list_repet[i].emg.shape[0] // length #integer division\n",
    "           \n",
    "            for j in range(nb_windows): \n",
    "                emg_seg = list_repet[i].emg[j*length:(j+1)*length]\n",
    "                label_seg = list_repet[i].label\n",
    "                \n",
    "                new_seg = segment(emg_seg,label_seg)\n",
    "                seg_data = np.append(seg_data,new_seg) \n",
    "           \n",
    "    if window_type == 'overlapped':\n",
    "        print(\"Not implemented yet\")\n",
    "    print(\"Data shape : \", seg_data.shape)\n",
    "    print(seg_data.shape)\n",
    "    return seg_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cdb651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  10400 repetitions of excercices in the data\n",
      "Data shape :  (12688,)\n",
      "(12688,)\n",
      "shape :  (12688,)\n",
      "[0.0003707  0.0949     0.00293797 0.00338769 0.00020374 0.109375\n",
      " 0.07421875]\n"
     ]
    }
   ],
   "source": [
    "list_seg = segmentation(list_repetition)\n",
    "print(\"shape : \", list_seg.shape)\n",
    "print(list_seg[0].get_features_by_channel(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33976c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca465574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dee3c9f9",
   "metadata": {},
   "source": [
    "# Classification part : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1882ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_feature = 7 \n",
    "\n",
    "input_feature = np.empty((nb_channel,list_seg.shape[0],nb_feature))\n",
    "\n",
    "l = list_seg.shape[0]\n",
    "for i in range(0,nb_channel):\n",
    "    print(i)\n",
    "    for j in range(0,list_seg.shape[0]):\n",
    "        print(j,\"/\",l)\n",
    "        input_feature[i][j] = list_seg[j].get_features_by_channel(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92270da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "shape (10, 12688)\n",
      "(12688, 7)\n",
      "35.0\n",
      "12688\n",
      "[[ 1.  0.  1. ... 52.  0.  0.]\n",
      " [ 1.  0.  1. ... 52.  0.  0.]\n",
      " [ 1.  0.  1. ... 52.  0.  0.]\n",
      " ...\n",
      " [ 1.  0.  1. ... 52.  0.  0.]\n",
      " [ 1.  0.  1. ... 52.  0.  0.]\n",
      " [ 1.  0.  1. ... 52.  0.  0.]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "label = np.empty((nb_channel,list_seg.shape[0]))\n",
    "print(list_seg[0].label[0])\n",
    "for i in range(0,nb_channel):\n",
    "    print(i)\n",
    "    for j in range(0,list_seg.shape[0]):\n",
    "        label[i][j] = list_seg[j].label[0]\n",
    "        \n",
    "print(\"shape\",label.shape)\n",
    "print(input_feature[0].shape)\n",
    "print(list_seg[11000].label[0])\n",
    "print(list_seg.shape[0])\n",
    "print(label)\n",
    "print(nb_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ae7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126880, 7)\n",
      "(126880,)\n"
     ]
    }
   ],
   "source": [
    "input_feature_all =np.empty((0,nb_feature))\n",
    "label_all=np.empty((0))\n",
    "for i in range(0,nb_channel):\n",
    "    input_feature_all = np.append(input_feature_all, input_feature[i], axis=0) #combination off all 10 chanels\n",
    "    label_all = np.append(label_all,label[i])\n",
    "print(input_feature_all.shape)\n",
    "print(label_all.shape)\n",
    "\n",
    "for i in range(0,nb_channel):\n",
    "    input_feature_all[:][:][i] = preprocessing.normalize([input_feature_all[:][:][i]])\n",
    "\n",
    "\"\"\"\n",
    "x_train= np.empty((0,nb_feature))\n",
    "y_train= np.empty((0))\n",
    "\n",
    "x_test= np.empty((0,nb_feature))\n",
    "y_test= np.empty((0))\n",
    "\n",
    "for i in range(0,nb_channel): # in this part , we study all the channels togheter\n",
    "    x_train_temp, x_test_temp, y_train_temp, y_test_temp = train_test_split(input_feature[i],label[i], test_size=0.1, \n",
    "                                                        shuffle=True ) \n",
    "    print(x_train_temp.shape)\n",
    "    print(y_train_temp.shape)\n",
    "    x_train= np.append(x_train,x_train_temp,axis=0)\n",
    "    y_train= np.append(y_train,y_train_temp,axis=0)\n",
    "    \n",
    "    x_test= np.append(x_test,x_test_temp,axis=0)\n",
    "    y_test= np.append(y_test,y_test_temp,axis=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "\"\"\"\n",
    "x_train_all, x_test_all, y_train_all, y_test_all = train_test_split(input_feature_all,label_all, test_size=0.2, \n",
    "                                                        shuffle=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd45e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([4,5,6])\n",
    "print(a.shape)\n",
    "\n",
    "a = np.append(a,b)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a317eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', gamma='auto')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='auto',kernel='rbf',class_weight='balanced',C=1.0, degree=3 ,max_iter= -1)\n",
    "clf.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "477fac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8383\n",
      "33.03515132408575 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7301fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.03515132408575 % accuracy\n",
      "[0.04689791 1.56340393 1.68144847 1.87946007 1.70692497 1.74582481\n",
      " 1.80506109 1.8557847  1.89620773 1.6120958  1.74106346 1.58540547\n",
      " 1.62440188 1.83094628 1.81360778 1.7442348  1.89808703 1.67703136\n",
      " 1.60399482 1.60399482 1.85758469 2.09308176 1.83974045 1.73161827\n",
      " 1.80847008 1.65672129 1.36602697 1.54823752 1.97033931 1.82397125\n",
      " 1.76350811 1.32354514 1.79659457 1.30728315 1.63549941 1.58540547\n",
      " 1.4541912  1.72227501 1.72537821 1.50091678 1.70086129 1.65672129\n",
      " 1.74106346 1.50800773 1.6993521  1.66103193 1.73790364 1.6495864\n",
      " 1.69634173 1.63271084 1.18293379 1.10384427 1.30283661]\n"
     ]
    }
   ],
   "source": [
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")\n",
    "print(clf.class_weight_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a674a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_feature[0],label[0], test_size=0.2, \n",
    "                                                        shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d42194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ozgun\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', gamma='auto', max_iter=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='auto',kernel='rbf',class_weight='balanced',C=1.0, degree=3 ,max_iter= 1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2c6bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0.15762925598991173 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test.shape[0]):\n",
    "    if clf.predict([x_test[i]])[0] - y_test[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca37c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linear = svm.SVC(gamma='auto',kernel='linear',class_weight='balanced',C=1.0, degree=3 ,max_iter= -1)\n",
    "clf_linear.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3285e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8287\n",
      "32.656841109709966 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_linear.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf4ed65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', gamma='auto', kernel='sigmoid')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sig = svm.SVC(gamma='auto',kernel='sigmoid',class_weight='balanced',C=1.0,max_iter= -1)\n",
    "clf_sig.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c47bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4757\n",
      "18.746059268600252 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_sig.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37d34349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c5847dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rfc = RandomForestClassifier(max_depth=None,class_weight='balanced')\n",
    "clf_rfc.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64cf62ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9867\n",
      "38.88319672131148 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_rfc.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3308795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- svm rbf increment C -----------------\n",
    "c_values = np.array([0.1 , 0.5 , 1 , 5, 10,15, 20, 50,100,150,300,500,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d0bfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- MlP -------------------------\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3fb8bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ozgun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(200, 1), max_iter=300,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=300 , hidden_layer_sizes =(200,1),solver='adam', activation = 'logistic')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a34ba682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10432\n",
      "41.10970996216898 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "910ceea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(400, 1), max_iter=300,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=300 , hidden_layer_sizes =(400,1),solver='adam', activation = 'logistic')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07254aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10428\n",
      "41.093947036569986 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d65a2d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 1), max_iter=300,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=300 , hidden_layer_sizes =(50,1),solver='adam', activation = 'logistic')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7a47f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10432\n",
      "41.10970996216898 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed907570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 1),\n",
       "              learning_rate_init=0.01, max_iter=300, random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=300 , hidden_layer_sizes =(50,1),solver='adam', activation = 'logistic', learning_rate_init=0.01)\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c853ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10441\n",
      "41.145176544766706 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e08bfa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 1),\n",
       "              learning_rate_init=0.1, max_iter=300, random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=300 , hidden_layer_sizes =(50,1),solver='adam', activation = 'logistic', learning_rate_init=0.1)\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "590ed8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10393\n",
      "40.95602143757881 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e33413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(200, 1), max_iter=500,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=500 , hidden_layer_sizes =(200,1),solver='adam', activation = 'logistic')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edc9ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10433\n",
      "41.11365069356873 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab3c9f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(200, 1), max_iter=500,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=500 , hidden_layer_sizes =(200,1),solver='adam', activation = 'tanh')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ad65852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10428\n",
      "41.093947036569986 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "797e040f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),\n",
       "              learning_rate_init=0.01, max_iter=500, random_state=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp_2 = MLPClassifier(random_state=0, max_iter=500 , hidden_layer_sizes =(100,100),solver='adam', activation = 'logistic', learning_rate_init=0.01)\n",
    "clf_mlp_2.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "803240ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10568\n",
      "41.645649432534675 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp_2.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae3ea876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ozgun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=500,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=500 , hidden_layer_sizes =(200),solver='adam', activation = 'tanh')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3e451c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10493\n",
      "41.35009457755359 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22186b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=200, max_iter=1000,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=0, max_iter=1000 , hidden_layer_sizes =(200),solver='adam', activation = 'tanh')\n",
    "clf_mlp.fit(x_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5194031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10536\n",
      "41.51954602774275 % accuracy\n"
     ]
    }
   ],
   "source": [
    "compt = 0\n",
    "for i in range(0,x_test_all.shape[0]):\n",
    "    if clf_mlp.predict([x_test_all[i]])[0] - y_test_all[i] == 0.0:\n",
    "        compt +=1\n",
    "print(compt)\n",
    "\n",
    "print(100*compt/x_test_all.shape[0],\"% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bf901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
